{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install ucimlrepo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Fe7uipjcKi_",
        "outputId": "04ebb11b-94a7-45a4-8501-9c2ecb6d80b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ucimlrepo\n",
            "  Downloading ucimlrepo-0.0.6-py3-none-any.whl (8.0 kB)\n",
            "Installing collected packages: ucimlrepo\n",
            "Successfully installed ucimlrepo-0.0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import pylab as pl\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import scipy.optimize as opt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import normalize, StandardScaler\n",
        "from sklearn.utils.class_weight import compute_sample_weight\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, \\\n",
        "f1_score, classification_report,ConfusionMatrixDisplay\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets\n",
        "import pickle\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n"
      ],
      "metadata": {
        "id": "ym5x5E3heMWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xKqSEi0wbQFJ"
      },
      "outputs": [],
      "source": [
        "digits = datasets.load_digits()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(digits.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKXXygKuehST",
        "outputId": "cb05fca5-74b0-4dfd-8223-e44d44236ada"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_, axes = plt.subplots(nrows=1, ncols=4, figsize=(10, 3))\n",
        "for ax, image, label in zip(axes, digits.images, digits.target):\n",
        "    ax.set_axis_off()\n",
        "    ax.imshow(image, cmap=plt.cm.gray_r, interpolation=\"nearest\")\n",
        "    ax.set_title(\"Training: %i\" % label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "id": "1k_4oB1wekAN",
        "outputId": "17f753e7-3da4-4c63-ada1-387a10e3da0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x300 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = digits.data\n",
        "y = digits.target"
      ],
      "metadata": {
        "id": "Imh9jbold_Gi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state=365, stratify=y)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X,y, test_size = 0.5, random_state=365, stratify=y)"
      ],
      "metadata": {
        "id": "rGKlSRRre53_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = np.asarray(y_train)\n",
        "y_test = np.asarray(y_test)\n",
        "y_val = np.asarray(y_val)"
      ],
      "metadata": {
        "id": "lzXoZRLFe_W5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = np.asarray(X_train)\n",
        "x_test = np.asarray(X_test)\n",
        "X_val = np.asarray(X_val)"
      ],
      "metadata": {
        "id": "PR0obA34fBxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print ('Train set:', x_train.shape,  y_train.shape)\n",
        "print ('Test set:', x_test.shape,  y_test.shape)\n",
        "print ('Validation set:', X_val.shape,  y_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jy8DFDVIfEz1",
        "outputId": "755ed3f8-0932-40af-c85e-3795566de7f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set: (1437, 64) (1437,)\n",
            "Test set: (899, 64) (899,)\n",
            "Validation set: (898, 64) (898,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "x_train = scaler.fit_transform(x_train)\n",
        "x_test =  scaler.transform(x_test)\n",
        "X_val =  scaler.transform(X_val)"
      ],
      "metadata": {
        "id": "rT2Vf8ULfGtG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train[0:1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMMtfwWefMft",
        "outputId": "a4cfb6d1-beaa-416a-96ce-6ea0d8d7208c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.00000000e+00, -3.43522453e-01, -1.08776211e+00,\n",
              "         5.18147431e-01,  5.00750353e-01, -8.50731595e-01,\n",
              "        -4.14062562e-01, -1.18360259e-01, -6.14166374e-02,\n",
              "        -6.23118365e-01, -1.35331965e+00,  1.00765120e+00,\n",
              "         7.80339320e-01, -1.34980940e+00, -5.27415197e-01,\n",
              "        -1.23461326e-01, -4.31180707e-02, -7.24233758e-01,\n",
              "         2.59160002e-02,  1.54091713e+00, -8.33759940e-01,\n",
              "        -1.26209985e+00, -5.56012746e-01, -1.10838322e-01,\n",
              "        -3.73326696e-02, -7.82510131e-01,  1.11850575e+00,\n",
              "         1.20945342e+00, -3.16262962e-01, -7.75552997e-01,\n",
              "        -6.28330510e-01, -5.28331981e-02,  0.00000000e+00,\n",
              "         1.89076623e-01,  1.31722859e+00,  9.31162753e-01,\n",
              "        -3.83603266e-01,  8.96120344e-01, -2.60895231e-01,\n",
              "         0.00000000e+00, -6.76445597e-02, -5.28955643e-01,\n",
              "         1.39154365e+00,  5.74674359e-01, -1.22628912e+00,\n",
              "         4.80034264e-01,  1.52388036e+00, -8.55950017e-02,\n",
              "        -2.94608883e-02, -4.13726082e-01,  2.65284929e-01,\n",
              "         8.43407606e-01, -4.59852056e-01,  1.20541442e+00,\n",
              "         1.29219499e+00, -1.98347258e-01,  0.00000000e+00,\n",
              "        -3.12229605e-01, -1.08574600e+00, -1.25818993e-03,\n",
              "         8.56067408e-01,  1.23565456e+00, -2.55156063e-01,\n",
              "        -1.86034069e-01]])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class FeedForwardNN:\n",
        "    def __init__(self, input_shape, num_classes):\n",
        "        self.input_shape = input_shape\n",
        "        self.num_classes = num_classes\n",
        "        self.weights = []\n",
        "        self.biases = []\n",
        "        self.activations = []\n",
        "        self.dropout_probs = []\n",
        "\n",
        "    def add_layer(self, num_units, activation, dropout_prob=None):\n",
        "        self.weights.append(np.random.randn(self.input_shape[-1], num_units))\n",
        "        self.biases.append(np.zeros((1, num_units)))\n",
        "        self.activations.append(activation)\n",
        "        self.dropout_probs.append(dropout_prob)\n",
        "        self.input_shape = (1, num_units)\n",
        "\n",
        "    def forward_pass(self, X, training=False):\n",
        "        activations = [X]\n",
        "        dropout_masks = []\n",
        "\n",
        "        for i in range(len(self.weights)):\n",
        "            Z = np.dot(activations[-1], self.weights[i]) + self.biases[i]\n",
        "\n",
        "            if self.activations[i] == 'relu':\n",
        "                A = np.maximum(0, Z)\n",
        "            elif self.activations[i] == 'softmax':\n",
        "                exps = np.exp(Z - np.max(Z, axis=1, keepdims=True))\n",
        "                A = exps / np.sum(exps, axis=1, keepdims=True)\n",
        "            else:\n",
        "                raise NotImplementedError(\"Activation function not implemented\")\n",
        "\n",
        "            if training and self.dropout_probs[i] is not None:\n",
        "                mask = (np.random.rand(*A.shape) < self.dropout_probs[i]) / self.dropout_probs[i]\n",
        "                A *= mask\n",
        "                dropout_masks.append(mask)\n",
        "\n",
        "            activations.append(A)\n",
        "\n",
        "        return activations[-1], dropout_masks\n",
        "\n",
        "    def compile_model(self):\n",
        "        def softmax(x):\n",
        "            exps = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
        "            return exps / np.sum(exps, axis=1, keepdims=True)\n",
        "\n",
        "        def relu(x):\n",
        "            return np.maximum(0, x)\n",
        "\n",
        "        activation_functions = {'relu': relu, 'softmax': softmax}\n",
        "\n",
        "        self.activations = [activation_functions[act] for act in self.activations]\n",
        "\n",
        "    def compile(self):\n",
        "        self.compile_model()\n",
        "\n",
        "    def fit(self, X, y, X_val, y_val, epochs, learning_rate):\n",
        "      train_losses = []\n",
        "      val_losses = []\n",
        "      val_accuracies = []\n",
        "\n",
        "      for epoch in range(epochs):\n",
        "\n",
        "          train_activations = [X]\n",
        "          for i in range(len(self.weights)):\n",
        "              Z_train = np.dot(train_activations[-1], self.weights[i]) + self.biases[i]\n",
        "              A_train = self.activations[i](Z_train)\n",
        "              train_activations.append(A_train)\n",
        "\n",
        "          train_output = train_activations[-1]\n",
        "\n",
        "\n",
        "          m_train = y.shape[0]\n",
        "          train_loss = -np.sum(np.log(train_output[np.arange(m_train), y] + 1e-10)) / m_train\n",
        "          train_losses.append(train_loss)\n",
        "\n",
        "\n",
        "          train_predictions = np.argmax(train_output, axis=1)\n",
        "          train_accuracy = np.mean(train_predictions == y)\n",
        "\n",
        "\n",
        "          val_activations = [X_val]\n",
        "          for i in range(len(self.weights)):\n",
        "              Z_val = np.dot(val_activations[-1], self.weights[i]) + self.biases[i]\n",
        "              A_val = self.activations[i](Z_val)\n",
        "              val_activations.append(A_val)\n",
        "\n",
        "          val_output = val_activations[-1]\n",
        "\n",
        "\n",
        "          m_val = y_val.shape[0]\n",
        "          val_loss = -np.sum(np.log(val_output[np.arange(m_val), y_val] + 1e-111)) / m_val\n",
        "          val_losses.append(val_loss)\n",
        "\n",
        "\n",
        "          val_predictions = np.argmax(val_output, axis=1)\n",
        "          val_accuracy = np.mean(val_predictions == y_val)\n",
        "          val_accuracies.append(val_accuracy)\n",
        "\n",
        "\n",
        "\n",
        "          dZ_train = train_output.copy()\n",
        "\n",
        "\n",
        "          dZ_train[np.arange(m_train), y] -= 1\n",
        "\n",
        "\n",
        "          for i in range(len(self.weights) - 1, -1, -1):\n",
        "\n",
        "              dW = np.dot(train_activations[i].T, dZ_train) / m_train\n",
        "              db = np.sum(dZ_train, axis=0, keepdims=True) / m_train\n",
        "\n",
        "\n",
        "              self.weights[i] -= learning_rate * dW\n",
        "              self.biases[i] -= learning_rate * db\n",
        "\n",
        "              if i > 0:\n",
        "                  dZ_train = np.dot(dZ_train, self.weights[i].T) * (train_activations[i] > 0)\n",
        "              else:\n",
        "                  dZ_train = np.dot(dZ_train, self.weights[i].T)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "          if epoch % 1 == 0:\n",
        "              print(f'Epoch {epoch}, Train Loss: {train_loss}, Train Accuracy: {train_accuracy}, Val Loss: {val_loss}, Val Accuracy: {val_accuracy}')\n",
        "\n",
        "      return train_losses, val_losses, val_accuracies\n",
        "\n",
        "\n",
        "    def evaluate(self, X, y):\n",
        "        predictions = np.argmax(self.forward_pass(X), axis=1)\n",
        "        accuracy = np.mean(predictions == y)\n",
        "        return accuracy\n",
        "\n",
        "def create_feedforward_nn(input_shape, num_classes):\n",
        "    model = FeedForwardNN(input_shape, num_classes)\n",
        "    model.add_layer(1024, 'relu')\n",
        "    model.add_layer(1024, 'relu')\n",
        "    model.add_layer(512, 'relu')\n",
        "    model.add_layer(512, 'relu')\n",
        "    model.add_layer(512, 'relu')\n",
        "    model.add_layer(256, 'relu')\n",
        "    model.add_layer(128, 'relu')\n",
        "    model.add_layer(64, 'relu')\n",
        "    model.add_layer(num_classes, 'softmax')\n",
        "    model.compile()\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "WnGYPDsYfOa9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (64, )\n",
        "num_classes = 10\n",
        "model = create_feedforward_nn(input_shape, num_classes)\n",
        "\n",
        "train_losses, val_losses, val_accuracies = model.fit(X_train, y_train, X_val, y_val, epochs=10, learning_rate=1e-4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQPPgLcDiLN5",
        "outputId": "f7f6da17-0ad1-4606-fbcb-d0c8ec68c4aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-62-9d4d98323535>:119: RuntimeWarning: invalid value encountered in multiply\n",
            "  dZ_train = np.dot(dZ_train, self.weights[i].T) * (train_activations[i] > 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Train Loss: 20.702435213269705, Train Accuracy: 0.10090466249130133, Val Loss: 235.66368677828143, Val Accuracy: 0.0779510022271715\n",
            "Epoch 1, Train Loss: nan, Train Accuracy: 0.09881697981906751, Val Loss: nan, Val Accuracy: 0.09910913140311804\n",
            "Epoch 2, Train Loss: nan, Train Accuracy: 0.09881697981906751, Val Loss: nan, Val Accuracy: 0.09910913140311804\n",
            "Epoch 3, Train Loss: nan, Train Accuracy: 0.09881697981906751, Val Loss: nan, Val Accuracy: 0.09910913140311804\n",
            "Epoch 4, Train Loss: nan, Train Accuracy: 0.09881697981906751, Val Loss: nan, Val Accuracy: 0.09910913140311804\n",
            "Epoch 5, Train Loss: nan, Train Accuracy: 0.09881697981906751, Val Loss: nan, Val Accuracy: 0.09910913140311804\n",
            "Epoch 6, Train Loss: nan, Train Accuracy: 0.09881697981906751, Val Loss: nan, Val Accuracy: 0.09910913140311804\n",
            "Epoch 7, Train Loss: nan, Train Accuracy: 0.09881697981906751, Val Loss: nan, Val Accuracy: 0.09910913140311804\n",
            "Epoch 8, Train Loss: nan, Train Accuracy: 0.09881697981906751, Val Loss: nan, Val Accuracy: 0.09910913140311804\n",
            "Epoch 9, Train Loss: nan, Train Accuracy: 0.09881697981906751, Val Loss: nan, Val Accuracy: 0.09910913140311804\n"
          ]
        }
      ]
    }
  ]
}